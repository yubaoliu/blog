#+STARTUP: showall
#+STARTUP: hidestars
#+LAYOUT: post
#+AUTHOR: Yubao Liu
#+CATEGORIES: blog
#+TITLE: SLAM Sumarry
#+DESCRIPTION: post
#+TAGS: slam
#+TOC: nil
#+OPTIONS: H:2 num:t tags:t toc:nil timestamps:nil email:t date:t body-only:t
#+DATE: 2019-09-05 木 08:53:03
#+EXPORT_FILE_NAME: 2019-09-05-slam.html
#+TOC: headlines 3
#+TOC: listings
#+TOC: tables

* Tutorial
- [[https://fzheng.me/2016/05/30/slam-review/][Brief Review on Visual SLAM: A Historical Perspective]]
- [[https://blog.csdn.net/heyijia0327][知行合一 [CSDN]​]]
  - 从零开始手写 VIO
- CMPUT631: Autonomous Robot Navigation: https://webdocs.cs.ualberta.ca/~zhang/c631/
  - Instructor: Dr. Hong Zhang, 407 Athabasca Hall, 492-7188, hzhang@ualberta.ca
  - Course Page: http://www.cs.ualberta.ca/~zhang/c631
  - https://webdocs.cs.ualberta.ca/~zhang/teaching.html

- Module 1: Least Squares Estimation and SLAM, http://www.diag.uniroma1.it/grisetti/teaching/lectures-ls-slam-master_2014_15/web/

Dip. Informatica e Sistemistica Sapienza Università di Roma

- Module 1: Least Squares Estimation and SLAM, http://www.diag.uniroma1.it/grisetti/teaching/lectures-ls-slam-master_2014_15/web/

- [[http://paopaorobot.org/bbs/read.php?tid=117][【泡泡机器人】公开课链接]]
- [[https://www.youtube.com/playlist?list=PLkcuHsB39IRLUxHvY89exXy3Y6xOxuHt_][George Hotz GeoHot Twitch Livecoding SLAM]] 
* Introduction
** What is SLAM?
SLAM: Simultaneous Localization and Mapping
- Estimate the pose of a robot and the map of the environment at the same time
- Localization: inferring location given a map
- Mapping: inferring a map given locations
- SLAM: learning a map and locating the robot simultaneously
- Disadvantage: lack of semantic information

SLAM是由“定位”（Localization)和“建图”（Mapping)两部分构成的。现在来看定位问题。
这个问题可以用基于特征的方法（feature-based）或直接的方法（direct method）来解.

[[https://i.imgur.com/mACMplo.png]]

SLAM Algorithms

 帧间匹配算法

-  ICP(Iterative Closest Point)
-  PI-ICP(Point-to-Line Iterative 小象学院slam无人驾驶Closest Point)
-  NDT(Normal Distribution Transfomation)
-  CSM(Correlation Scan Match), 2008 ## 回环检测
-  Scan-to-Scan
-  Scan-to-Map
-  Map-to-Map

#+CAPTION: 两轮差速底盘的运动学模型
[[https://i.imgur.com/JqjACFN.png]]

** Rigid Assumption
The assumption of scene rigidity is typical in SLAM algorithms. Such a strong assumption limits the use of most visual SLAM systems in populated real-world environ- ments, which are the target of several relevant applications like service service robotics or autonomous vehicles.\cite{Bescos2018}

** Chalenges in Visual SLAM
- Low-contrast; textureless image regions
- occlusions
- Violations of brightness constancy (e.g., specular reflections)
- Really large baselines (foreshortening adn appearance change)
- Camera calibration errors

* Semantic SLAM

** QuadricSLAM
- [[http://www.semanticslam.ai/][SemanticSLAM.ai]]

* SLAM Algorithms
** RT-SLAM
- [[https://github.com/damarquezg/rtslam][RT-SLAM]]
** SLAMTB
- [[https://github.com/damarquezg/SLAMTB][SLAMTB]] 
EKF-SLAM TOOLBOX FOR MATLAB
** Openvslam
- [[https://github.com/xdspacelab/openvslam][xdspacelab/openvslam]]
** PTAM
- [[https://github.com/Oxford-PTAM/PTAM-GPL][PTAM]]
** RTAB Map
- [[http://introlab.github.io/rtabmap/][RTAB-Map]]
- https://github.com/introlab/rtabmap_ros.git ; http://wiki.ros.org/rtabmap_ros
** Loop Closure
- [[https://github.com/dorian3d/DLoopDetector][dorian3d/DLoopDetector]]
** maskfusion

** Openkarto
- [[https://github.com/skasperski/OpenKarto/tree/master/source][skasperski/OpenKarto]]
** Type Conversion Between Eigen, G2O, OpenCV
- https://github.com/gaoxiang12/rgbd-slam-tutor2/blob/master/include/converter.h
- https://github.com/raulmur/ORB_SLAM2/blob/master/include/Converter.h
- [[http://www.justlive.vip/blog/article/details/3136][Blog-g2o、Eigen、Mat矩阵类型转换-Just Live]]
- https://blog.csdn.net/hzwwpgmwy/article/details/80712967

** Loop Closure
- [[https://github.com/craymichael/CNN_LCD][craymichael/CNN_LCD]]
 CNNs for Loop-Closure Detection on the Oxford New College and City Centre Datasets

* Challenges in Visual SLAM
** Initialization
** Data association
 - Feature Matching
** Optical Flow
   FlowNet FlowNetSimple, FlowNetCorr

   PWC-Net
** Depth Eistimation
- GC-Net
- MonoDepth 
Unsupervised Monocular Depth Estimation with ...
- SFMLearner - Unsupervised

** No semantic information
- Mask R-CNN (Instance Segmentation)
** Localization
https://www.visuallocalization.net/
** Others
- Deep TAM
- Code SLAM
- GN NET
- VI NET IMU
- NetVLAD
- VSO 
* Kinect Fusion
** Tutorial
- [[https://wlsdzyzl.top/2019/01/25/3D-Reconstruction%E2%80%94%E2%80%94TSDF-volume-reconstruction/][3D Reconstruction——TSDF volume reconstruction]]
- [[https://courses.cs.washington.edu/courses/cse571/15au/slides/14-mapping-tsdf.pdf][CSE-571 Mapping	and	Modeling Using	Truncated	Signed	Distance Functions]]
- [[https://www.alanzucconi.com/2016/07/01/signed-distance-functions/][Volumetric Rendering: Signed Distance Functions]]
Signed Distance Functions

** Volumetric Representation
Volume就是一个体空间。
** SDF 与 TSDF
- TSDF( Truncated Signed Distance Functions ) — 截断符号距离函数
- SDF （Signed Distance Functions）— 符号距离函数

一个体素的SDF值，是它到最近的表面的距离，如果它在表面前（也就是距离相机更近），它是正值，如果在表面后，则为负值。

* RGBD SLAM
- yubaoliu/rgbdslam_v2: git@github.com:yubaoliu/rgbdslam_v2.git
* RTAB MAP
** Resource
- [[https://blog.51cto.com/remyspot/1784914][SLAM: RtabMap中文解析]]
- [[http://introlab.github.io/rtabmap/][RTAB-Map-gitio]]
- [[http://introlab.github.io/rtabmap/][RTxAB-Map]]
- http://wiki.ros.org/rtabmap_ros  

#+begin_export html
<iframe width="640" height="480" src="https://www.youtube.com/embed/AMLwjo80WzI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="true"></iframe>
#+end_export

** ROS version
#+begin_example
sudo apt-get install ros-kinetic-rtabmap-ros
#+end_example

** With ORB SLAM2
#+begin_export  sh
export ORB_SLAM2_ROOT_DIR=/home/yubao/data/catkin_ws/src/ORB_SLAM2
#+end_export

I see this error:
#+begin_example
/usr/bin/ld: cannot find -lpangolin
collect2: error: ld returned 1 exit status
rtabmap_ros/CMakeFiles/rtabmap_rgbd_sync.dir/build.make:1222: recipe for target '/home/yubao/data/catkin_ws/devel/lib/rtabmap_ros/rgbd_sync' failed
make[2]: *** [/home/yubao/data/catkin_ws/devel/lib/rtabmap_ros/rgbd_sync] Error 1
CMakeFiles/Makefile2:16659: recipe for target 'rtabmap_ros/CMakeFiles/rtabmap_rgbd_sync.dir/all' failed
make[1]: *** [rtabmap_ros/CMakeFiles/rtabmap_rgbd_sync.dir/all] Error 2
make[1]: *** Waiting for unfinished jobs....
#+end_example

* GSLAM
- [[https://github.com/zdzhaoyong/GSLAM][zdzhaoyong/GSLAM]]
* SFM
- sfm-github: https://github.com/topics/sfm
* DynaSLAM
** Introduction
- Project: https://bertabescos.github.io/DynaSLAM/
- [[https://github.com/BertaBescos/DynaSLAM.git][BertaBescos/DynaSLAM]]
- [[https://blog.csdn.net/qq_38589460/article/details/86549662][CSDN ORB-SLAM2到dynaSLAM编译]]
<iframe width="640" height="480" src="https://www.youtube.com/embed/EabI_goFmQs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
** Compile
#+begin_src bash
git clone https://github.com/BertaBescos/DynaSLAM.git
cd DynaSLAM

chmod +x build.sh
./build.sh
#+end_src
** Paper
Bescos, B., Facil, J. M., Civera, J., & Neira, J. (2018). DynaSLAM: Tracking, Mapping, and Inpainting in Dynamic Scenes. IEEE Robotics and Automation Letters, 3(4), 4076–4083. https://doi.org/10.1109/LRA.2018.2860039 \cite{Bescos2018}
[[https://youtu.be/EabI_goFmQs][Youtube-demo]]
** Abstract
The assumption of scene rigidity is typical in SLAM algorithms. Such a strong assumption limits the use of most visual SLAM systems in populated real-world environ- ments, which are the target of several relevant applications like service service robotics or autonomous vehicles.

In this paper we present DynaSLAM, a visual SLAM system
that, building on ORB-SLAM2, adds the capabilities of 
- dynamic object detection and 
- background inpainting. 

DynaSLAM is robust in dynamic scenarios for monocular, stereo and RGB-D configurations. 

We are capable of detecting the moving objects either by multi-view geometry, deep learning or both. 

**Inpainting**: **Having a static map of the scene** allows inpainting the frame background that has been occluded by such dynamic objects.

** Notes
第三部分我理解的是求基础矩阵用了ransac，所以基础矩阵更符合静态点的运动模型。当前点离这个基础矩阵计算出的极线越远就说明动态效果越大
* RDSLAM
- [[http://www.zjucvg.net/rdslam/rdslam.html][RDSLAM: Robust Dynamic SLAM]]
* Mask-SLAM
** Paper
Kaneko, M., Iwami, K., Ogawa, T., Yamasaki, T., & Aizawa, K. (2018). Mask-SLAM: Robust feature-based monocular SLAM by masking using semantic segmentation. IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, 2018-June, 371–379. https://doi.org/10.1109/CVPRW.2018.00063
* SOURCE CODE
- zssjh/semantic_slam: https://github.com/zssjh/semantic_slam.git
 ORB-SLAM2 combined with yolov3 object detection, considering the relationship among objects
- 

* ORB_SLAM2_SSD_Semantic
- [[https://github.com/Ewenwan/ORB_SLAM2_SSD_Semantic][Ewenwan/ORB_SLAM2_SSD_Semantic]]
* Visual-Inertial (VIO)
** Common VIO Solutions

#+CAPTION: common vio solutions
[fn:1]
http://qiniu.yubaoliu.cn/vio-solutions-compare.png 
** Variables of Interest and dynamical model



** References
- [[https://blog.csdn.net/wangshuailpp/article/details/78461171][VINS技术路线与代码详解]]

* Useful tools for the RGB-D benchmark
- https://vision.in.tum.de/data/datasets/rgbd-dataset/tools#evaluation
** ABSOLUTE TRAJECTORY ERROR (ATE)
** RELATIVE POSE ERROR (RPE)
** Generating a point cloud from images
#+begin_example
usage: generate_pointcloud.py [-h] rgb_file depth_file ply_file

This script reads a registered pair of color and depth images and generates a
colored 3D point cloud in the PLY format.

positional arguments:
  rgb_file    input color image (format: png)
  depth_file  input depth image (format: png)
  ply_file    output PLY file (format: ply)

optional arguments:
  -h, --help  show this help message and exit
#+end_example

* References
- Kinect Fusion 之 TSDF, http://adastaybrave.com/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/2018/09/02/Kinect-Fusion-%E4%B9%8B-TSDF/

* Footnotes

[fn:1] https://www.bilibili.com/video/av44472237?from=search&seid=15063536043439842457 

