#+STARTUP: showall
#+STARTUP: hidestars
#+LAYOUT: post
#+AUTHOR: Yubao Liu
#+CATEGORIES: slam
#+TITLE: ORB SLAM
#+DESCRIPTION: post
#+TAGS: orb slam2
#+TOC: nil
#+OPTIONS: H:2 num:t tags:t toc:nil timestamps:nil email:t date:t body-only:t
#+DATE: 2019-09-28 土 19:16:17
#+EXPORT_FILE_NAME: 2019-09-28-ORB-SLAM.html
#+TOC: headlines 3
#+TOC: listings
#+TOC: tables
* Introduction
** ORB SLAM 1
- Mono Camera
- 2015
- ROS support

** ORB SLAM 2
- 2017
- Mono, stereo and RGBD Camera
- Can build without ROS
- [[https://github.com/gaoxiang12/ORBSLAM2_with_pointcloud_map.git][ORBSLAM2_with_pointcloud_map]]
- yubaoliu/YB_ORB_SLAM: git@github.com:yubaoliu/YB_ORB_SLAM.git

* ORB Feature
** Introduction
ORB(Oriented Fast and Rotated BRIEF)

ORB
- Oriented FAST -> KeyPoint
- Rotated BRIEF -> Descriptor

[[post:ORBSLAM-ORB-Feature.png]] [fn:1]
** Fast
[[post:ORBSLAM-Fast.png]] [fn:1]

- 第一步： 通過比較東西南北四個點的灰度值進行初步的筛选，排除明顯不是觸點的點。
- 第二步：應用觸點檢測算法

[[post:ORBSLAM-FAST-Algorith.png]]  [fn:1]

但我們會發現觸點扎堆現象：
[[post:ORBSLAM-cornerFeatureProblem.png]] [fn:1]

非最大值抑制去除扎堆觸點中的較差者。

- 圓弧半徑上，n值最大者保留爲觸點。
- 圓弧半徑上， 閾值t最大者保留爲觸點
- 圓弧半徑上， 各連續像素塊灰度值和中心灰度值的絕對值差最在者保留爲觸點。
 [[post:ORBSLAM-ORB-Rule3.png]] [fn:1]

** Brief
[[post:ORBSLAM-brief.png]] [fn:1]

[[post:ORBSLAM-Brief-2.png]] [fn:1]

** oFAST
oFast: Oriented Fast
[[post:oFAST.png]] [fn:1]

** rBRIEF
rBRIEF: Rotation-Aware BRIEF
[[post:rBRIEF.png]] [fn:1]

** Source Code
*** 計算ORB特徵與描述子
#+begin_src src
void ORBextractor::operator()(InputArray _image, InputArray _mask, vector<KeyPoint> &_keypoints,
                              OutputArray _descriptors)
#+end_src
*** 轉爲灰度圖
#+begin_src cpp
cv::Mat Tracking::GrabImageRGBD(const cv::Mat &imRGB, const cv::Mat &imD, const double &timestamp):

 if (mImGray.channels() == 3)
    {
        if (mbRGB)
            cvtColor(mImGray, mImGray, CV_RGB2GRAY);
        else
            cvtColor(mImGray, mImGray, CV_BGR2GRAY);
    }
    
 assert(image.type() == CV_8UC1);
#+end_src
*** ComputePyramid
#+begin_src cpp
ComputePyramid(image);
#+end_src
*** 計算特徵並使用OctTree來存儲
#+begin_src cpp
ComputeKeyPointsOctTree(allKeypoints);
#+end_src
*** 高斯瀘波
#+begin_src cpp
   Mat workingMat = mvImagePyramid[level].clone();
        GaussianBlur(workingMat, workingMat, Size(7, 7), 2, 2, BORDER_REFLECT_101);
#+end_src
*** computeDescriptors
#+begin_src cpp
computeDescriptors(workingMat, keypoints, desc, pattern);
#+end_src

* Notes
** Twc
- 表示当前相机光心在世界坐标系下的三维坐标
- 表示从相机坐标系到世界坐标系的转化
$$P_w = T_{wc} * P_c$$
** Tcw
- 表示从世界坐标系到相机坐标系的转化
$$P_c = T_{cw} * P_w$$

* Build
** ROS Wrapper
#+begin_example
rosdep update
cd ORB_SLAM2/Examples/ROS/YB_ORB_SLAM/build
cmake ..
make
#+end_example

* Publish TF
[[https://github.com/raulmur/ORB_SLAM2/issues/597][Get Pose Information from ORBSLAM #597]]
** Method 1
#+begin_src cpp

#include"../../../include/System.h"

#include"../../../include/Converter.h"
#include <tf2_ros/transform_broadcaster.h>
#include <geometry_msgs/TransformStamped.h>
#include <tf2/LinearMath/Quaternion.h>
#include <tf/transform_listener.h>


    cv::Mat Tcw = mpSLAM->TrackRGBD(cv_ptrRGB->image,cv_ptrD->image,cv_ptrRGB->header.stamp.toSec());
    if(Tcw.empty())
        return;

   //publish TF
    static tf2_ros::TransformBroadcaster br;
    geometry_msgs::TransformStamped transformStamped;
    transformStamped.header.stamp = cv_ptrRGB->header.stamp;
    transformStamped.header.frame_id = "world";
    transformStamped.child_frame_id = "camera_pose";


    cv::Mat Rwc = Tcw.rowRange(0, 3).colRange(0,3).t(); // world to camera
    cv::Mat twc = -Rwc*Tcw.rowRange(0,3).col(3);

    vector<float> q = ORB_SLAM2::Converter::toQuaternion(Rwc);

    transformStamped.transform.translation.x = twc.at<float>(0);
    transformStamped.transform.translation.x = twc.at<float>(1);
    transformStamped.transform.translation.x = twc.at<float>(2);

    transformStamped.transform.rotation.x = q[0];
    transformStamped.transform.rotation.y = q[1];
    transformStamped.transform.rotation.z = q[2];
    transformStamped.transform.rotation.w = q[3];

    br.sendTransform(transformStamped);
#+end_src

** Method2
#+begin_example
 cv::Mat Twc = Tcw.inv();
 cv::Mat Rwc = Twc.rowRange(0, 3).colRange(0, 3);
cv::Mat twc = Twc.rowRange(0, 3).col(3);

#+end_example
* ORB-SLAM: a Versatile and Accurate Monocular SLAM System

** Abstract

This paper presents ORB-SLAM, a feature-based monocular simultaneous
localization and mapping (SLAM) system that operates in real time, in
small and large indoor and outdoor environments.

The system is robust to severe motion clutter, allows wide baseline loop
closing and relocalization, and includes full automatic initialization.

Building on excellent algorithms of recent years, we designed from
scratch a novel system that uses the same features for all SLAM tasks:

- tracking,
- mapping,
- relocalization,
- and loop closing.

A survival of the fittest strategy that selects the points and keyframes
of the reconstruction leads to excellent robustness and generates a
compact and trackable map that only grows if the scene content changes,
allowing lifelong operation. We present an exhaustive evaluation in 27
sequences from the most popular datasets. ORB-SLAM achieves
unprecedented performance with respect to other state-of-the-art
monocular SLAM approaches. For the benefit of the community, we make the
source code public.

* orb-slam2_with_semantic_label
[[https://github.com/yubaoliu/orb-slam2_with_semantic_label][Github]]

[[https://i.loli.net/2019/03/05/5c7e1f3c00e52.png]]
* orb_slam2_ros
- [[https://github.com/appliedAI-Initiative/orb_slam_2_ros][appliedAI-Initiative/orb_slam_2_ros]]
* Resources
- [[https://www.cnblogs.com/shang-slam/p/6733322.html][ORB-SLAM跑通笔记本摄像头]]
  环境：Ubuntu 14.04 + ROS indigo + ORB-SLAM2 (Thinkpad T460s)
- [[http://www.cnblogs.com/luyb/p/5357790.html][路游侠blog 代码解读]]
- orb-slam2代码总结 http://www.pianshen.com/article/156343678/
 - orb-slam2代码总结（四）特征点匹配
 - ORBSlam2学习研究-Tracking流程
 - orbslam2段错误 (核心已转储)
 - ORBSLAM2 理论部分_高斯金字塔（二）
 - Realsense D435基于ROS跑通ORBSLAM2
 - 用MYNTEYE双目惯导相机跑通ORBSLAM2和OKVIS
 - 浅谈opencv库中的特征点提取与匹配(四)——ORB特征点提取详解
- ORB-SLAM2代码阅读笔记（九）:ORBmatcher
https://www.jianshu.com/p/7e46f15f115a

-  一索哥传奇 https://zhehangt.github.io/
- sylvester0510 https://me.csdn.net/u010128736
- [[https://www.bilibili.com/video/av7102994/][orb-slam的简单重构-冯兵]]
- 【泡泡机器人】公开课链接（实时更新） http://paopaorobot.org/bbs/read.php?tid=117
- ORB特征提取, https://www.bilibili.com/video/av21684482/?spm_id_from=333.788.videocard.7
- 胡君的个人博客, http://hujun1413.github.io/2018/11/09/VSLAM/ORB-SLAM2/
- gaoxiang12/ORBSLAM2_with_pointcloud_map, https://github.com/gaoxiang12/ORBSLAM2_with_pointcloud_map.git
- Qee_S, https://sqn175.cn/archive.html

* Question
** Play bag file bug no map
- Camera only rotates w/o translation and point clouds is not showing on Map Viewer

Refer: [[https://github.com/raulmur/ORB_SLAM2/issues/534][Camera only rotates w/o translation and point clouds is not showing on Map Viewer]]

- Solution

Setting DepthMapFactor to 1 of TUM yalm file solved this problem

#+begin_src 
rosbag play --clock   rgbd_dataset_freiburg1_xyz.bag  /camera/rgb/image_color:=/camera/rgb/image_raw /camera/depth/image:=/camera/depth/image_raw
#+end_src



This paper presents ORB-SLAM, a feature-based monocular simultaneous localization and mapping (SLAM) system that operates in real time, in small and large indoor and outdoor environments.

The system is robust to severe motion clutter, allows wide baseline loop closing and relocalization, and includes full automatic initialization.

Building on excellent algorithms of recent years, we designed from scratch a novel system that uses the same features for all SLAM tasks:

- tracking,
- mapping,
- relocalization,
- and loop closing.

 A survival of the fittest strategy that selects the points and keyframes of the reconstruction leads to excellent robustness and generates a compact and trackable map that only grows if the scene content changes, allowing lifelong operation. We present an exhaustive evaluation in 27 sequences from the most popular datasets. ORB-SLAM achieves unprecedented performance with respect to other state-of-the-art monocular SLAM approaches. For the benefit of the community, we make the source code public. 

* Footnotes

[fn:1] vSLAM实践课程--ORB_SLAM2--class(1-4), https://www.bilibili.com/video/av69148695/?p=6
 
